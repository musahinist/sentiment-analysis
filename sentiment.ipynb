{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python38132bitc310fee83e8549a2b99a412f8b82a3bf",
   "display_name": "Python 3.8.1 32-bit"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Duygu Analizi (Python NLTK sentiment analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Duygu analizi: \n",
    "Yapacağımız işlem duyguların kategorik olarak düzenlenmesi ve duyguları pozitif, negatif yada nötr olarak sınıflandırılma işlemidir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'np'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-b9d30d7fbc15>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m \u001b[1;31m#Bu kütüphane lineer cebir için kullandığımız kütüphane fonksiyonlarını içeriyor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m \u001b[1;31m# verilerimizi işlemek için pandas kütüphanasini kullanıyoruz(örn pd.read_scv)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m \u001b[1;31m#Bu işlem ile verilerimizi eğitim ve test(%70-%30) olacak çekilde bölüyoruz\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'np'"
     ]
    }
   ],
   "source": [
    "import numpy as np #Bu kütüphane lineer cebir için kullandığımız kütüphane fonksiyonlarını içeriyor\n",
    "import pandas as pd # verilerimizi işlemek için pandas kütüphanasini kullanıyoruz(örn pd.read_scv)\n",
    "from np.random import rand\n",
    "from np.random import randn\n",
    "from sklearn.model_selection import train_test_split #Bu işlem ile verilerimizi eğitim ve test(%70-%30) olacak çekilde bölüyoruz\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.classify import SklearnClassifier\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from subprocess import check_output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd # verilerimizi işlemek için pandas kütüphanasini kullanıyoruz(örn pd.read_scv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "veri = pd.read_csv('Sentiment.csv')\n",
    "#Veri setinde sadece ihtiyacım olacak sütunlar kalıyor.\n",
    "veri = veri[['text', 'sentiment']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "İlk olarak şimdi elimde bulunan veri setini eğitim ve test verileri olacak şekilde ikiye bölüyorum test için %10 ve eğitim için %90 olacak şekilde verileri ayırıyorum, bu çalışmada sadece duyguların pozitif mi yoksa negatifmi olduğu ile ilgileniyorum dolayısı ile nötr duyguları de veri setimden çıkarıyorum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Veri Setimi Eğitim ve test verilerine ayırıyorum\n",
    "train, test = train_test_split(veri, test_size = 0.1)\n",
    "#Sonra Veri seti içerisindeki Nötr duyguları çıkarıyorum\n",
    "train = train[train.sentiment !=\"Neutral\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bir sonraki edım için eğitim setimdeki verilerden Nötr verileri çıkardım dolayısı ile görselleştirme işlemi daha da kolaylaştı. Daha sonra veri seti içerisinde #hashtag olan değerleri ve link içeren değerleri temizliyorum. Şimdi artık en empatik değerleri WordCloud dan Negatif ve Pozitif olacak şekilde görselleştiriyorum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos = train[ train['sentiment'] == 'Positive']\n",
    "train_pos = train_pos['text']\n",
    "train_neg = train[ train['sentiment'] == 'Negative']\n",
    "train_neg = train_neg['text']\n",
    "\n",
    "def wordcloud_draw(data, color = 'black'):\n",
    "    words = ' '.join(data)\n",
    "    cleaned_word = \" \".join([word for word in words.split()\n",
    "                            if 'http' not in word\n",
    "                                and not word.startswith('@')\n",
    "                                and not word.startswith('#')\n",
    "                                and word != 'RT'\n",
    "                            ])\n",
    "    wordcloud = WordCloud(stopwords=STOPWORDS,\n",
    "                      background_color=color,\n",
    "                      width=2500,\n",
    "                      height=2000\n",
    "                     ).generate(cleaned_word)\n",
    "    plt.figure(1,figsize=(13, 13))\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "print(\"Pozirif Kelimeler\")\n",
    "wordcloud_draw(train_pos,'white')\n",
    "print(\"Negatif Kelimeler\")\n",
    "wordcloud_draw(train_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pozitif kelime setinde aşağıdaki kelimeleri ve ifadeleri fark etmek ilginç: hakikat , güçlü , meşru , birlikte , aşk , iş (truth, strong, legitimate, together, love, job)\n",
    "\n",
    "Benim yorumumda, insanlar ideal adaylarının doğru, meşru, iyi ve kötünün üzerinde olduğuna inanmaya eğilimlidirler.\n",
    "Aynı şekilde Negatif kelimeler içerisindeki : etki, haberler,asansor müziği,hayal kırıklığı, yumuşaktop, makyaj yapmak, Kiraz toplama, denemek gibi kelimelerin olması da ilginç.\n",
    "\n",
    "Anladığım kadarıyla insanlar kararlı bir şekilde harekete geçmeyi başardılar ve azarlanan adayların çok yumuşak ve vişne almayı düşündüklerini söylediler.\n",
    "\n",
    "Görselleştirmeden sonra eğitim setinden hashtag, link ve sonlandırıcı kelimeleri çıkardım. Stop Word : Arama sorgularında kullanılmak üzere önemli bir önem taşımayan kelimelerdir. Genellikle bu kelimeler gereksiz bilgi döndürdüğü için arama sorgularından filtrelenir. (the, for, this vb.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets =[]\n",
    "stopwords_set = set(stopwords.words(\"english\"))\n",
    "\n",
    "for index, row in train.iterrows():\n",
    "    words_filtered = [e.lower() for e in row.text.split() if len(e) >= 3]\n",
    "    words_cleaned = [word for word in words_filtered\n",
    "                    if 'http' not in word\n",
    "                    and not word.startswith('@')\n",
    "                    and not word.startswith('#')\n",
    "                    and word != 'RT']\n",
    "    words_without_stopwords = [word for word in words_cleaned if not word in stopwords_set]\n",
    "    tweets.append((words_cleaned, row.sentiment))\n",
    "    \n",
    "test_pos = test[test['sentiment'] == 'Positive']\n",
    "test_pos = test_pos['text']\n",
    "test_neg = test[test['sentiment'] == 'Negative']\n",
    "test_neg = test_neg['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bir sonraki adım olarak, nltk lib ile adlandırılan özellikleri ilk önce sık dağılımı ölçüp ve sonuçta oluşan anahtar kelimeleri çıkardım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kelimelerin özelliklerini çıkarıyorum.\n",
    "def get_words_in_tweets(tweets):\n",
    "    all =[]\n",
    "    for (words, sentiment) in tweets:\n",
    "        all.extend(words)\n",
    "    return all\n",
    "def get_word_features(wordlist):\n",
    "    wordlist = nltk.FreqDist(wordlist)\n",
    "    features = wordlist.keys()\n",
    "    return features\n",
    "w_features = get_word_features(get_words_in_tweets(tweets))\n",
    "\n",
    "def extract_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in w_features:\n",
    "        features['containts(%s)' % word] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "En sık tekrar eden kelimeleri görselleştiriyorum. Genellikle kelimeler tartışma merkezi etrafında toplanıyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud_draw(w_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud_draw(w_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk Naive Bayes sınıfandırmacıyı kullanarak kelimeleri özelliklerine göre sınıflandırdım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes sınıflandırıcıyı eğitiyorum\n",
    "training_set = nltk.classify.apply_features(extract_features, tweets)\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Son olarak, çok akıllı olmayan metriklerle, sınıflandırıcı algoritmasının nasıl puanlandırma yaptığını ölçmeye çalıştım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_cnt = 0\n",
    "pos_cnt = 0\n",
    "for obj in test_neg:\n",
    "    res = classifier.classify(extract_features(obj.split()))\n",
    "    if(res == 'Negative'):\n",
    "        neg_cnt = neg_cnt + 1\n",
    "for obj in test_pos:\n",
    "    res = classifier.classify(extract_features(obj.split()))\n",
    "    if(res == 'Positive'):\n",
    "        pos_cnt = pos_cnt + 1\n",
    "\n",
    "print('[Negative]: %s/%s' % (len(test_neg), neg_cnt))\n",
    "print('[Positive]: %s/%s' % (len(test_pos), pos_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Son değerlendirme.\n",
    "Bu projede nltk ve NaiveBayes Machine Learning algoritmasının Sentiment Analizi için ne kadar iyi performans gösterdiğini merak ettim. Benim deneyimime göre, olumsuz yorumlar için oldukça iyi çalışıyor. Sorunlar tweet'ler ironik olduğunda, alaycı referansa sahip veya kendi zor bir içeriğe sahip olduğunda ortaya çıkar.\n",
    "\n",
    "Aşağıdaki tweet'i düşünün:\n",
    "\n",
    "\"Muhaha, Liberallerin Trump'u yok edememesi ne kadar üzücü. Daha önce de düşündüğünüz gibi, sad ve destroy ifadeleri, anlam ve bağlamı göz önüne alındığında bu tweet pozitif olsa da, değerlendirmeyi büyük ölçüde etkilemektedir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}